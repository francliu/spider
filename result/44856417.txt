ubuntu自带java环境，不需要安装。
1.SSH和无密码登录
安装SSH客户端
sudoapt-getinstallopenssh-client
sudoapt-getinstallopenssh-server
生成无密码的“公私钥”对：
suhadoop
ssh-keygen-tdsa-P''-f~/.ssh/id_dsa
cat~/.ssh/id_dsa.pub&gt;&gt;~/.ssh/authorized-keys
chmod600~/.ssh/authorized_keys
确认是否成功：
sshlocalhost
2.Hadoop的下载与解压
http://mirror.metrocast.net/apache/hadoop/common/hadoop-1.2.1/
到hadoop.apache.org上下载Hadoop的安装文件，笔者使用的是“hadoop-1.2.1.tar”。
在发布式安装模式下，所有服务器Hadoop的安装目录需要一样。笔者安装的位置为/home/liujianfei/hadoop，使用解压命令如下：
tar-zxvfhadoop-1.2.1.tar.gz-C/home/liujianfei/hadoop
mv/home/liujianfei/hadoop/hadoop-1.2.1/home/liujianfei/hadoop/hadoop-1.2.1
chown-Rhadoop:hadoop/home/liujianfei/hadoop/hadoop
3、配置Hadoop
修改hadoop目录下conf/hadoop-env.sh的环境变量，在末尾添加：
exportJAVA_HOME=/usr
exportHADOOP_HEAPSIZE=256
exportHADOOP_PID_DIR=/home/$USER/pids
修改hadoop目录下conf/core-site.xml的配配置在&lt;configuration&gt;标签中添加如下内容：
&lt;property&gt;
&lt;name&gt;fs.default.name&lt;/name&gt;
&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
&lt;/property&gt;
修改hadoop目录下conf/hdfs-site.xml的配置文件，在&lt;configuration&gt;标签中添加如下内容：
&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
修改hadoop目录下conf/mapred-site.xml的配置文件，在&lt;configuration&gt;标签中添加如下内容：
&lt;property&gt;
&lt;name&gt;mapred.job.tracker&lt;/name&gt;
&lt;value&gt;localhost:9001&lt;/value&gt;
&lt;/property&gt;
4、执行
在使用一个分布式文件系统前需要对其进行&#26684;式
./bin/hadoopnamenode-format
启动Hadoop守护进程
./bin/start-all.sh

关闭Hadoop守护进程
./bin/stop-all.sh
Hadoop守护进程的日志写入到${HADOOP_LOG_DIR}目录（默认为logs下）。
浏览NameNode和JobTracker的网络借口，他们的地址默认为：
NameNode-http://localhost:50070/
JobTracker-http://localhost:50030/
成功安装后输入jps,可以看到六个线程
4647JobTracker

4824TaskTracker

4556SecondaryNameNode

4356DataNode

9007Jps

4076NameNode
ubuntu自带java环境，不需要安装。
1.SSH和无密码登录
安装SSH客户端
sudoapt-getinstallopenssh-client
sudoapt-getinstallopenssh-server
生成无密码的“公私钥”对：
suhadoop
ssh-keygen-tdsa-P''-f~/.ssh/id_dsa
cat~/.ssh/id_dsa.pub&gt;&gt;~/.ssh/authorized-keys
chmod600~/.ssh/authorized_keys
确认是否成功：
sshlocalhost
2.Hadoop的下载与解压
http://mirror.metrocast.net/apache/hadoop/common/hadoop-1.2.1/
到hadoop.apache.org上下载Hadoop的安装文件，笔者使用的是“hadoop-1.2.1.tar”。
在发布式安装模式下，所有服务器Hadoop的安装目录需要一样。笔者安装的位置为/home/liujianfei/hadoop，使用解压命令如下：
tar-zxvfhadoop-1.2.1.tar.gz-C/home/liujianfei/hadoop
mv/home/liujianfei/hadoop/hadoop-1.2.1/home/liujianfei/hadoop/hadoop-1.2.1
chown-Rhadoop:hadoop/home/liujianfei/hadoop/hadoop
3、配置Hadoop
修改hadoop目录下conf/hadoop-env.sh的环境变量，在末尾添加：
exportJAVA_HOME=/usr
exportHADOOP_HEAPSIZE=256
exportHADOOP_PID_DIR=/home/$USER/pids
修改hadoop目录下conf/core-site.xml的配配置在&lt;configuration&gt;标签中添加如下内容：
&lt;property&gt;
&lt;name&gt;fs.default.name&lt;/name&gt;
&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
&lt;/property&gt;
修改hadoop目录下conf/hdfs-site.xml的配置文件，在&lt;configuration&gt;标签中添加如下内容：
&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
修改hadoop目录下conf/mapred-site.xml的配置文件，在&lt;configuration&gt;标签中添加如下内容：
&lt;property&gt;
&lt;name&gt;mapred.job.tracker&lt;/name&gt;
&lt;value&gt;localhost:9001&lt;/value&gt;
&lt;/property&gt;
4、执行
在使用一个分布式文件系统前需要对其进行&#26684;式
./bin/hadoopnamenode-format
启动Hadoop守护进程
./bin/start-all.sh

关闭Hadoop守护进程
./bin/stop-all.sh
Hadoop守护进程的日志写入到${HADOOP_LOG_DIR}目录（默认为logs下）。
浏览NameNode和JobTracker的网络借口，他们的地址默认为：
NameNode-http://localhost:50070/
JobTracker-http://localhost:50030/
成功安装后输入jps,可以看到六个线程
4647JobTracker

4824TaskTracker

4556SecondaryNameNode

4356DataNode

9007Jps

4076NameNode
